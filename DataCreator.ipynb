{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os: Proporciona funciones para interactuar con el sistema operativo, como manejar rutas de archivos y directorios.\n",
    "import os\n",
    "\n",
    "# time: Permite acceder a funciones que manejan el tiempo, como pausas (sleep) o tomar el tiempo actual.\n",
    "import time\n",
    "\n",
    "# uuid: Usado para generar identificadores únicos universales (UUIDs), que son útiles para nombres de archivos únicos, por ejemplo.\n",
    "import uuid\n",
    "\n",
    "# cv2: OpenCV para operaciones relacionadas con visión por computadora, como procesamiento de imágenes y video.\n",
    "import cv2\n",
    "\n",
    "# tensorflow as tf: Biblioteca para crear modelos de aprendizaje automático, especialmente redes neuronales profundas.\n",
    "import tensorflow as tf\n",
    "\n",
    "# json: Biblioteca para trabajar con datos en formato JSON, útil para serializar y deserializar datos.\n",
    "import json\n",
    "\n",
    "# numpy as np: Proporciona soporte para arrays y matrices grandes y funciones matemáticas de alto nivel para operar con estos.\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib.pyplot as plt: Proporciona una interfaz para crear gráficos y visualizaciones estáticas, animadas e interactivas en Python.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# albumentations as alb: Biblioteca de aumento de imágenes que proporciona diversas técnicas de transformación de imágenes para mejorar los conjuntos de datos de entrenamiento de visión por computadora.\n",
    "import albumentations as alb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Colación de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar la red neuronal necesitamos un conjunto de imágenes con los puntos iris etiquetatdos.\n",
    "\n",
    "Para ello la idea que se tiene es realizar un video y que de dicho video se selleciónene 80 imagenes que luego mediante la aplicación de **labelme** se etiquetaran los puntos (ojo derecho y izquierdo), para obtener sus cordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'data'\n",
    "number_images = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) C:\\b\\abs_f8n1j3l9l0\\croot\\opencv-suite_1691622637237\\work\\modules\\highgui\\src\\window.cpp:1267: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enric\\Documents\\1 - Inteligencia Artificial\\Proyectos\\Iris-Detection-Tensorflow\\DataCreator.ipynb Celda 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/1%20-%20Inteligencia%20Artificial/Proyectos/Iris-Detection-Tensorflow/DataCreator.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(imgname, frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/1%20-%20Inteligencia%20Artificial/Proyectos/Iris-Detection-Tensorflow/DataCreator.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Mostrar el frame capturado en una ventana\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/1%20-%20Inteligencia%20Artificial/Proyectos/Iris-Detection-Tensorflow/DataCreator.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mframe\u001b[39;49m\u001b[39m'\u001b[39;49m, frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/1%20-%20Inteligencia%20Artificial/Proyectos/Iris-Detection-Tensorflow/DataCreator.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Esperar medio segundo antes de capturar la siguiente imagen\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/1%20-%20Inteligencia%20Artificial/Proyectos/Iris-Detection-Tensorflow/DataCreator.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) C:\\b\\abs_f8n1j3l9l0\\croot\\opencv-suite_1691622637237\\work\\modules\\highgui\\src\\window.cpp:1267: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "# Iniciar la captura de video desde la cámara predeterminada (cámara 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Bucle para capturar un número específico de imágenes\n",
    "for imgnum in range(number_images):\n",
    "    # Imprimir en consola el número de la imagen que se está capturando\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "\n",
    "    # Capturar un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Generar un nombre único para la imagen utilizando uuid y guardar la imagen\n",
    "    imgname = os.path.join(IMAGES_PATH, f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "\n",
    "    # Mostrar el frame capturado en una ventana\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Esperar medio segundo antes de capturar la siguiente imagen\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Comprobar si se presionó la tecla 'q' para salir del bucle\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar todas las ventanas de OpenCV\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Crear el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    # Leer el archivo de imagen desde la ruta proporcionada y almacenarlo como un conjunto de bytes.\n",
    "    # 'x' es la ruta de la imagen que se va a cargar.\n",
    "    byte_img = tf.io.read_file(x)\n",
    "\n",
    "    # Decodificar la imagen en formato JPEG de los bytes leídos.\n",
    "    # Esto convierte los datos de la imagen de su formato de archivo (JPEG) a un tensor que TensorFlow puede utilizar.\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "\n",
    "    # Retornar el tensor de la imagen decodificada.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Mover las imágenes y anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar a través de las carpetas 'train', 'test', y 'val'\n",
    "for folder in ['train', 'test', 'val']:\n",
    "    # Iterar sobre cada archivo en la subcarpeta 'images' dentro de cada carpeta 'train', 'test', 'val'\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "\n",
    "        # Construir el nombre del archivo JSON correspondiente al archivo de imagen\n",
    "        # Se asume que el nombre del archivo de imagen y del archivo JSON son iguales excepto la extensión\n",
    "        filename = file.split('.')[0] + '.json'\n",
    "\n",
    "        # Construir la ruta completa del archivo JSON en la carpeta 'labels'\n",
    "        existing_filepath = os.path.join('data', 'labels', filename)\n",
    "\n",
    "        # Comprobar si el archivo JSON existe\n",
    "        if os.path.exists(existing_filepath):\n",
    "            # Construir la nueva ruta donde se debería mover el archivo JSON\n",
    "            # Esta ruta coloca el archivo JSON en una subcarpeta 'labels' dentro de 'train', 'test' o 'val'\n",
    "            new_filepath = os.path.join('data', folder, 'labels', filename)\n",
    "\n",
    "            # Mover (reemplazar) el archivo desde su ubicación actual a la nueva ruta\n",
    "            os.replace(existing_filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Modificar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el módulo 'albumentations' como 'alb'. Este módulo se utiliza para la \n",
    "# augmentación de imágenes, es decir, para aplicar transformaciones que generan \n",
    "# variaciones de las imágenes existentes.\n",
    "\n",
    "augmentor = alb.Compose([\n",
    "    # Aplica un recorte aleatorio en la imagen con un ancho y alto de 450 píxeles.\n",
    "    alb.RandomCrop(width=450, height=450), \n",
    "\n",
    "    # Realiza un volteo horizontal (espejo) de la imagen con una probabilidad del 50%.\n",
    "    alb.HorizontalFlip(p=0.5), \n",
    "\n",
    "    # Ajusta aleatoriamente el brillo y el contraste de la imagen con una probabilidad del 20%.\n",
    "    alb.RandomBrightnessContrast(p=0.2),\n",
    "\n",
    "    # Aplica una corrección gamma aleatoria a la imagen con una probabilidad del 20%.\n",
    "    # Esto puede afectar la iluminación de la imagen.\n",
    "    alb.RandomGamma(p=0.2), \n",
    "\n",
    "    # Cambia aleatoriamente los canales de color RGB de la imagen con una probabilidad del 20%.\n",
    "    alb.RGBShift(p=0.2), \n",
    "\n",
    "    # Realiza un volteo vertical de la imagen con una probabilidad del 50%.\n",
    "    alb.VerticalFlip(p=0.5)\n",
    "], \n",
    "# Configura los parámetros para las transformaciones que involucran puntos clave.\n",
    "# 'format' especifica el formato de los puntos clave (en este caso 'xy' para coordenadas cartesianas).\n",
    "# 'label_fields' especifica los campos de etiquetas que se deben utilizar con los puntos clave.\n",
    "keypoint_params=alb.KeypointParams(format='xy', label_fields=['class_labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train', 'test', 'val']: \n",
    "    # Itera sobre cada imagen en el directorio especificado.\n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        # Lee la imagen usando OpenCV.\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        # Inicializa clases y coordenadas por defecto.\n",
    "        classes = [0,0]\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "\n",
    "        # Construye la ruta al archivo de etiquetas correspondiente a la imagen.\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        \n",
    "        # Verifica si el archivo de etiquetas existe.\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "                \n",
    "        # Procesa las etiquetas, extrayendo clases y coordenadas de los puntos clave.\n",
    "            if label['shapes'][0]['label']=='LeftEye': \n",
    "                classes[0] = 1\n",
    "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if label['shapes'][0]['label']=='RightEye':\n",
    "                classes[1] = 1\n",
    "                coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if len(label['shapes']) > 1:     \n",
    "                if label['shapes'][1]['label'] =='LeftEye': \n",
    "                    classes[0] = 1 \n",
    "                    coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "                if label['shapes'][1]['label'] =='RightEye': \n",
    "                    classes[1] = 1\n",
    "                    coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "            \n",
    "            np.divide(coords, [640,480,640,480])\n",
    "                \n",
    "        try: \n",
    "            for x in range(120):\n",
    "                keypoints = [(coords[:2]), (coords[2:])]\n",
    "                augmented = augmentor(image=img, keypoints=keypoints, class_labels=['LeftEye','RightEye'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                annotation['class'] = [0,0]\n",
    "                annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['keypoints']) > 0: \n",
    "                        for idx, cl in enumerate(augmented['class_labels']):\n",
    "                            if cl == 'LeftEye': \n",
    "                                annotation['class'][0] = 1 \n",
    "                                annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
    "                            if cl == 'RightEye': \n",
    "                                annotation['class'][1] = 1 \n",
    "                                annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
    "                                \n",
    "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
